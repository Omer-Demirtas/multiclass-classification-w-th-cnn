{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 14:05:19.237969: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import datetime\n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor='loss',patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r EPOCH\n",
    "%store -r STEPS_PER_EPOCH\n",
    "%store -r VALIDATION_STEPS\n",
    "\n",
    "%store -r X_train\n",
    "%store -r y_train\n",
    "%store -r X_test \n",
    "%store -r y_test \n",
    "\n",
    "%store -r train_dir \n",
    "%store -r test_dir\n",
    "%store -r model_dir\n",
    "\n",
    "%store -r class_names\n",
    "%store -r class_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "layers.Conv2D(\n",
    "    filters: int, the dimension of the output space (the number of filters in the convolution).kernel_size: int or tuple/list of 2 integer, specifying the size of the convolution window.\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc_loss(x):  \n",
    "  acc = x.history[\"acc\"]\n",
    "  val_acc = x.history[\"val_acc\"]\n",
    "  loss = x.history[\"loss\"]\n",
    "  val_loss = x.history[\"val_loss\"]\n",
    "  \n",
    "  print(\"acc =\", acc[-1])\n",
    "  print(\"val_acc = \",val_acc[-1])\n",
    "  print(\"loss =\", loss[-1])\n",
    "  print(\"val_loss =\", val_loss[-1])\n",
    "  epochs = range(1, len(acc) + 1)\n",
    "  fig=plt.figure()\n",
    "  plt.subplot(2,1,1)\n",
    "  plt.plot(epochs, acc, \"bo\", label=\"Training acc\")\n",
    "  plt.plot(epochs, val_acc, \"b\", label=\"Validation acc\")\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Acc')\n",
    "  plt.title(\"Training and Validation Accuracy\")\n",
    "\n",
    "  plt.subplot(2,1,2)\n",
    "  plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "  plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "  plt.title(\"Training and Validation Loss\")\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.legend()\n",
    "  fig.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  # Define model\n",
    "  model = models.Sequential()\n",
    "\n",
    "  # Layer 1\n",
    "  model.add(\n",
    "    layers.Conv2D(\n",
    "      64,(3,3),\n",
    "      padding='same',\n",
    "      activation='relu',\n",
    "      input_shape=(32,32,3)\n",
    "      )\n",
    "  )\n",
    "\n",
    "  model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "  # Layer 3\n",
    "  model.add(\n",
    "    layers.Conv2D(\n",
    "      64,(3, 3), \n",
    "      padding='same',\n",
    "      activation='relu'\n",
    "    )\n",
    "  )\n",
    "\n",
    "  model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "  # Layer 4\n",
    "  model.add(\n",
    "    layers.Conv2D(\n",
    "      128,(3,3),\n",
    "      padding='same',\n",
    "      activation='relu'\n",
    "    )\n",
    "  )\n",
    "\n",
    "  model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Layer 5\n",
    "  model.add(\n",
    "    layers.Conv2D(\n",
    "      128,(3,3),\n",
    "      padding='same',\n",
    "      activation='relu'\n",
    "    )\n",
    "  )\n",
    "\n",
    "  # Dense layer:\n",
    "  model.add(layers.Flatten())\n",
    "  model.add(layers.Dropout(0.50))\n",
    "  model.add(layers.Dense(256, activation='relu'))\n",
    "  model.add(layers.Dropout(0.50))\n",
    "  model.add(layers.Dense(256, activation='relu'))\n",
    "  model.add(layers.Dense(len(class_names), activation='softmax'))\n",
    "\n",
    "  # Compile\n",
    "  model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adamax(lr=5e-3), metrics=['acc'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Model Summary\n",
    "def model_summary(model):\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model):\n",
    "    train_datagen=ImageDataGenerator(rescale=1./255)\n",
    "    test_datagen= ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    #veri zenginleştirilmesi yapılıyor overfitting engellemek için\n",
    "    datagen = ImageDataGenerator(\n",
    "                zoom_range=0.2,\n",
    "                horizontal_flip=True,\n",
    "                rescale=1./255)\n",
    "\n",
    "    #Train:\n",
    "    train_generator = datagen.flow_from_directory(train_dir,\n",
    "                                            target_size = (32,32),\n",
    "                                            batch_size =20,\n",
    "                                            class_mode = 'categorical')\n",
    "\n",
    "    test_generator = datagen.flow_from_directory(test_dir,\n",
    "                                            target_size = (32,32),\n",
    "                                            batch_size = 20,\n",
    "                                            class_mode = 'categorical')\n",
    "\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        callbacks=callback,\n",
    "        steps_per_epoch=STEPS_PER_EPOCH,                              \n",
    "        epochs=EPOCH,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=VALIDATION_STEPS\n",
    "    ) \n",
    "\n",
    "    plot_acc_loss(history)\n",
    "\n",
    "    current_time = datetime.datetime.now()\n",
    "\n",
    "    # Format the date and time\n",
    "    formatted_time = current_time.strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "\n",
    "    model.save(model_dir + 'cifar100_' + formatted_time + '.h5')\n",
    "    model.save('cifar100.h5')\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
